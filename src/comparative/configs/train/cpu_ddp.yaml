# src/comparative/configs/train/cpu_ddp.yaml
_target_: pytorch_lightning.Trainer
accelerator: cpu
devices: 6                  # One per physical core (matches your CPU)
strategy: ddp                    # True multi-process DDP
max_epochs: 15
log_every_n_steps: 5
default_root_dir: D:/COmparative_Study_of_Multimodal_Represenations/src/comparative/checkpoints/
accumulate_grad_batches: 4
